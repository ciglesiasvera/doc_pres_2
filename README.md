# Pipeline ETL de Analytics E-commerce

## ğŸ¯ PropÃ³sito del Negocio
Centraliza la data de ventas dispersa de mÃºltiples fuentes de e-commerce para reducir el tiempo de generaciÃ³n de reportes de 3 dÃ­as a 4 horas, mejorando la toma de decisiones comerciales con insights accionables en tiempo real.

## ğŸ— Arquitectura de Alto Nivel
Diagrama conceptual para entendimiento rÃ¡pido:

```
[Fuentes: API REST E-commerce] --> (Ingesta: Airflow) --> (Procesamiento: Spark) --> [DW: Snowflake]
       â†“
[PostgreSQL Transaccional] --> (ValidaciÃ³n) --> (Limpieza) --> (Enriquecimiento) --> [S3 Data Lake]
```

## ğŸš€ Quick Start (Para impacientes)
Comandos exactos para levantar el entorno en menos de 5 minutos:

```bash
$ git clone https://github.com/ciglesiasvera/doc_pres_2.git
$ cd doc_pres_2
$ python -m venv dp_venv
$ source dp_venv/bin/activate
$ pip install -r requirements.txt
$ make setup
$ make run-local
```

## ğŸ”§ GuÃ­a de Desarrollo
### Prerrequisitos
- Python 3.9+
- Docker y Docker Compose
- Airflow 2.5+
- Spark 3.3+

### Variables de Entorno
Copiar `.env.example` a `.env` y configurar las credenciales necesarias.

```bash
$ cp .env.example .env
$ nano .env
```

### Estructura del Proyecto
```
doc_pres_2/
â”œâ”€â”€ dags/                    # DAGs de Airflow
â”œâ”€â”€ src/                     # CÃ³digo fuente Python
â”œâ”€â”€ tests/                   # Pruebas unitarias
â”œâ”€â”€ docs/                    # DocumentaciÃ³n adicional
â”œâ”€â”€ docker/                  # ConfiguraciÃ³n Docker
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš ï¸ Troubleshooting ComÃºn
- **Error: Connection refused to PostgreSQL**  
  Verificar que el servicio de PostgreSQL estÃ© corriendo y las credenciales en `.env` sean correctas.

- **Error: Spark session not initialized**  
  Asegurar que las variables de entorno `SPARK_HOME` y `JAVA_HOME` estÃ©n configuradas.

- **Error: Airflow scheduler not picking up DAGs**  
  Revisar permisos de archivos en la carpeta `dags/` y reiniciar el scheduler.

---

# DocumentaciÃ³n TÃ©cnica del Pipeline ETL

## Arquitectura del Pipeline ETL
### VisiÃ³n General
El pipeline ETL procesa datos de e-commerce para generar insights de negocio, transformando datos crudos en informaciÃ³n estructurada lista para anÃ¡lisis.

### Componentes Principales
#### 1. ExtracciÃ³n (Extract)
**PropÃ³sito**: Obtener datos desde mÃºltiples fuentes externas.  
**TecnologÃ­as**: SQLAlchemy, Requests, PyArrow.  
**Fuentes**:
- API REST de plataforma e-commerce
- Base de datos transaccional PostgreSQL
- Archivos CSV de proveedores externos

**CaracterÃ­sticas**:
- ExtracciÃ³n incremental para eficiencia
- Reintentos automÃ¡ticos en caso de fallos
- ValidaciÃ³n bÃ¡sica de integridad

#### 2. TransformaciÃ³n (Transform)
**PropÃ³sito**: Limpiar, validar y enriquecer datos.  
**Operaciones**:
- Limpieza de valores faltantes y outliers
- NormalizaciÃ³n de formatos
- CÃ¡lculo de mÃ©tricas derivadas (total_venta, margen, etc.)
- ValidaciÃ³n de reglas de negocio

#### 3. Carga (Load)
**PropÃ³sito**: Almacenar datos procesados para consumo.  
**Destinos**:
- Data Warehouse (PostgreSQL dimensional)
- Data Lake (S3 con particionado)
- Cache (Redis para dashboards)

### Flujo de Datos
```
API E-commerce â†’ ValidaciÃ³n â†’ Limpieza â†’ Enriquecimiento â†’ DW
       â†“              â†“         â†“            â†“            â†“
PostgreSQL DB â†’ NormalizaciÃ³n â†’ Reglas Neg. â†’ Agregaciones â†’ S3
```

### Decisiones ArquitectÃ³nicas
#### Escalabilidad
- **Horizontal**: MÃºltiples workers de Airflow
- **Vertical**: Recursos apropiados por componente
- **Auto-scaling**: Basado en carga de trabajo

#### Fiabilidad
- **Reintentos**: Configurados por tipo de error
- **Circuit breakers**: Para dependencias externas
- **Backups**: Diarios con retenciÃ³n de 30 dÃ­as

#### Mantenibilidad
- **Modularidad**: Componentes independientes
- **ConfiguraciÃ³n externa**: Variables de entorno
- **Logging estructurado**: Para debugging

### MÃ©tricas de Ã‰xito
#### Performance
- Latencia end-to-end: < 30 minutos
- Throughput: 1000 registros/segundo
- Disponibilidad: 99.9% uptime

#### Calidad
- Completitud: > 99.5% de datos vÃ¡lidos
- Exactitud: < 0.1% error rate
- Consistencia: Validaciones automÃ¡ticas

## Runbook Operativo
### Inicio Diario
1. Verificar conectividad de fuentes
2. Validar espacio en disco (> 20% libre)
3. Check health de servicios crÃ­ticos
4. Ejecutar pipeline manual si automÃ¡tico falla

### Monitoreo
- Dashboard Grafana con mÃ©tricas en tiempo real
- Alertas PagerDuty para incidentes crÃ­ticos
- Logs centralizados en ELK stack

### RecuperaciÃ³n de Desastres
- Backups diarios del DW
- Reprocesamiento histÃ³rico posible
- Failover automÃ¡tico entre regiones

---

## ğŸ‘¥ Autores
- **Cristian Iglesias Vera** - [ciglesiasvera](https://github.com/ciglesiasvera) - ciglesiasvera@gmail.com

## ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ¤ Contribuciones
Las contribuciones son bienvenidas. Por favor, lee `CONTRIBUTING.md` para detalles sobre el proceso de contribuciÃ³n.